# 一、进程池的基本概念

- 创建一个进程池，通过`Pool`类执行任务

# 二、构造函数

- `class multiprocessing.pool.Pool(processes, initializer, initargs, maxtasksperchild, context)`
  - processes：进程的数量，如果为None，则为`os.cpu_count()`，也就是当前cpu的内核数量
  - 如果 *initializer* 不为 `None`，则每个工作进程将会在启动时调用 `initializer(*initargs)`
  - *maxtasksperchild* 是一个工作进程在它退出或被一个新的工作进程代替之前能完成的任务数量，为了释放未使用的资源。默认的 *maxtasksperchild* 是 `None`，意味着工作进程寿与池齐
    - 通常来说，[`Pool`](https://docs.python.org/zh-cn/3/library/multiprocessing.html#multiprocessing.pool.Pool) 中的 Worker 进程的生命周期和进程池的工作队列一样长。一些其他系统中（如 Apache, mod_wsgi 等）也可以发现另一种模式，他们会让工作进程在完成一些任务后退出，清理、释放资源，然后启动一个新的进程代替旧的工作进程。 [`Pool`](https://docs.python.org/zh-cn/3/library/multiprocessing.html#multiprocessing.pool.Pool) 的 *maxtasksperchild* 参数给用户提供了这种能力。
  - *context* 可被用于指定启动的工作进程的上下文。通常一个进程池是使用函数 `multiprocessing.Pool()` 或者一个上下文对象的 [`Pool()`](https://docs.python.org/zh-cn/3/library/multiprocessing.html#multiprocessing.pool.Pool) 方法创建的。在这两种情况下， *context* 都是适当设置的

# 三、Api

- `apply`(func, args=(), kwds={})

  - 使用 *args* 参数以及 *kwds* 命名参数调用 *func* , **它会在返回结果前阻塞**。这种情况下，`apply_async()` 更适合并行化工作。另外 *func* 只会在**一个进程池中的一个工作进程中执行**。**一个进程的崩溃会影响其它的进程，apply_async 不会**

    ```python
    def func(*args, **kwargs):
      print(args)
      print(kwargs)
      time.sleep(1)
      print("in func!!!!")
    
    
    ms.set_start_method('fork')
    with Pool(processes=3) as pool:  # 上下文管理
      pool.apply(func, (123, 345), {'a': 1, 'b': 2}) # 注意参数的传递必须为元组和字典
      print('in pool!!!')
    
    # 123, 345)
    # {'a': 1, 'b': 2}
    # 会阻塞在线程函数之中                  
    # in func!!!!
    # in pool!!!
    
    ```

- apply_async(func, args, kwds, callback, error_callback)

  - apply()方法的变体，它返回一个AsyncResult对象

  - 如果指定了 *callback* , 它必须是一个接受单个参数的可调用对象。当执行成功时， *callback* 会被用于处理执行后的返回结果，否则，调用 *error_callback* 

    - 需要回调函数的场景：
      - 进程池中任何一个任务一旦处理完了，就立即告知主进程：我好了，你可以处理我的结果了。主进程则调用一个函数去处理该结果，该函数即回调函数
      - 我们可以把耗时间（阻塞）的任务放到进程池中，然后指定回调函数（主进程负责执行），这样主进程在执行回调函数时就省去了I/O的过程，直接拿到的是任务的结果
    - **异常回调函数的参数为调用函数抛出的异常，正常回调函数为调用函数返回的值**

  - 如果指定了 *error_callback* , 它必须是一个接受单个参数的可调用对象。当目标函数执行失败时， 会将抛出的异常对象作为参数传递给 *error_callback* 执行。回调函数应该立即执行完成，否则会阻塞负责处理结果的线程。

    ```python
      # 回调函数，注意必须可以接收参数
      def cb(*args, **kwargs):
        print("Run !!!!")
    
      def func(*args, **kwargs):
        print(args)
        print(kwargs)
        time.sleep(1)
        print("in func!!!!")
    
    
      ms.set_start_method('fork')
      with Pool(processes=3) as pool:  # 上下文管理
        pool.apply_async(func, (123, 345), {'a': 1, 'b': 2}, callback=cb) # 注意参数的传递必须为元组和字典
        print('in pool!!!')
        time.sleep(1)
    
    # 不会阻塞在线程函数之中
    # in pool!!!
    # (123, 345)
    # {'a': 1, 'b': 2}
    # in func!!!!
    # Run !!!! # 回调函数
    ```

    

- map(func, iterable,chunksize)

  - 内置`map()`函数的等效函数

  - 只支持一个可迭代对象，`starmap`支持多个可迭代对象，该函数会**一直阻塞到函数运行完成**

  - map将可迭代对象切割成很多块传递给进程池，可通过chunksize设置块的大小.**也就是说一个进程大约运行几次函数**

  - 请注意，对于非常长的可迭代对象，它可能会导致占用大量内存。可以通过 Consider using imap() 或者 imap_unordered() 来提高效率

    ```python
    def func(args):
      print(args, ":", os.getpid())
    
    
    ms.set_start_method('fork')
    with Pool(processes=3) as pool:  # 上下文管理
      pool.map(func, [1, 2, 3, 4, 5, 6, 7], 3)  # 注意参数的传递必须为元组和字典
    
    # 设置chunksize=3,3个进程拿到了任务
    # 1 : 42793
    # 2 : 42793
    # 3 : 42793
    # 4 : 42794
    # 5 : 42794
    # 6 : 42794
    # 7 : 42795
    
    # 设置chunksize=7
    # 1 : 42574
    # 2 : 42574
    # 3 : 42574
    # 4 : 42574
    # 5 : 42574
    # 6 : 42574
    # 7 : 42574
    
    
    # 返回结果会被组合成list
    def func(args):
      ret = f"({args}:{os.getpid()})"
      return ret
    
    ms.set_start_method('fork')
    with Pool(processes=3) as pool:  # 上下文管理
      ret = pool.map(func, [1, 2, 3, 4, 5, 6, 7], 3)  # 注意参数的传递必须为元组和字典
      print(ret) # ['(1:46086)', '(2:46086)', '(3:46086)', '(4:46087)', '(5:46087)', '(6:46087)', '(7:46087)']
    ```

    

- map_async(func, iterable, chunksize, callback, error_callback)

  - map()方法的变体，它返回一个AsyncResult对象

  - 参数含义和上述apply_async一样

  - **不会阻塞**

    ```python
    from multiprocessing import Pool
    import time
    import multiprocessing as ms
    import os
    
    
    # 回调函数，注意必须可以接收参数
    def cb(*args, **kwargs):
      print("Run !!!!")
    
    
    def func(args):
      time.sleep(11)
    
      ret = f"{args}:{os.getpid()}"
      return ret
    
    
    ms.set_start_method('fork')
    with Pool(processes=3) as pool:  # 上下文管理
      ret = pool.map_async(func, [1, 2, 3, 4, 5, 6, 7], 5)  # 注意参数的传递必须为元组和字典
      print(ret.get())  # 阻塞的获取结果(这里是主线程，因此阻塞的是组线程)
    
    # ['1:44795', '2:44795', '3:44795', '4:44795', '5:44795', '6:44796', '7:44796']
    ```

    

- imap(func, iterable, chunksize)

  - map 的前一个版本

  -  chunksize参数与map()方法使用的参数相同

  - 对于非常长的可迭代对象，使用大的chunksize值可以比使用默认值1更快地完成任务

  - 当chunksize为1时，返回的迭代器的`next(timeout)`方法有一个超时选项设置，如果不能在规定时间内得到函数的执行结果，将会引发异常

    ```python
    from multiprocessing import Pool
    import time
    import multiprocessing as ms
    import os
    
    
    def func(args):
      ret = f"{args}:{os.getpid()}"
      return ret
    
    
    ms.set_start_method('fork')
    with Pool(processes=3) as pool:  # 上下文管理
      ret = pool.imap(func, [1, 2, 3, 4, 5, 6, 7], 3)  # 注意参数的传递必须为元组和字典
      print(ret.__next__())
      print(ret.__next__())
    
    # map的迭代器版本
    # 1:47064
    # 2:47064
    ```

    

- imap_unordered(func, iterable, chunksize)

  - 和imap一样，唯一的区别是返回的迭代器是无序的(只有一个进程时是有序的)

- startmap(func, iterable, chunksize)

  - 和map一样，不过 *iterable* 中的每一项会被解包再作为函数参数

    ```python
    [(1,2), (3, 4)] results in [func(1,2), func(3,4)]
    
    
    
    def func(*args, **kwargs):
      ret = f"{args}:{os.getpid()}"
      return ret
    
    
    ms.set_start_method('fork')
    with Pool(processes=3) as pool:  # 上下文管理
      ret = pool.starmap(func, [[1, 2, 3, [1, 2, 3]], [4, 4, 5, 6], [43, 432]],
                         3) 
      print(ret)
    
    # 将其打散，在传给函数,只可打散一次
    # ['(1, 2, 3, [1, 2, 3]):47863', '(4, 4, 5, 6):47863', '(43, 432):47863']
    ```

- starmap_async(func, iterable, chunksize, callback, error_callback)

  - starmap()和map_async()的组合
  - 将可迭代对象打散一次，然后传递给函数，然后再像`map_async`返回一个AsyncResult

- close()

  -  防止向池提交任何任务。一旦所有任务完成，工作进程将退出

- terminate()

  - 停止工作进程，当进程池对象被垃圾回收时，会立即调用这个函数

- join()

  - 等待工作进程退出。在使用join()之前必须调用close()或terminate()

- 小结![image-20220822192542094](https://yrecord.oss-cn-hangzhou.aliyuncs.com/picture/202208221925956.png)

# 四、进程池返回对象 AsyncResult

## 4.1  构造函数

- `class `multiprocessing.pool.``AsyncResult``
  - `Pool.apply_async` 和 `Pool.map_async`的返回对象

## 4.2 API 接口

- get(timeout)

  - 用于获取执行结果,timeout 为None则表示阻塞等待获取结果
  
- wait(timeout)

  - 阻塞，直到返回结果，或者 *timeout* 秒后超时

- ready()

  - 返回状态，是否已经完成

- successfil()

  - 判断调用是否已经完成并且未引发异常。 如果还未完成则将引发 `ValueError`

    

# 五、注意事项

- 池对象的方法只能由创建池的进程调用
- `Queue` 无法在池中使用
  - [解决办法](https://blog.csdn.net/tpoy0099/article/details/50324485?ops_request_misc=&request_id=&biz_id=102&utm_term=%E6%97%A0%E6%B3%95%E5%9C%A8%E8%BF%9B%E7%A8%8B%E6%B1%A0%E4%B8%AD%E4%BD%BF%E7%94%A8%E9%98%9F%E5%88%97Queue%E7%9A%84&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-50324485.142^v42^pc_rank_34,185^v2^control&spm=1018.2226.3001.4187)

- 警告
  - [`multiprocessing.pool`](https://docs.python.org/zh-cn/3/library/multiprocessing.html#module-multiprocessing.pool) 对象具有需要正确管理的内部资源 （像任何其他资源一样），具体方式是将进程池用作**上下文管理器(with pool ......)**，或者手动调用 [`close()`](https://docs.python.org/zh-cn/3/library/multiprocessing.html#multiprocessing.pool.Pool.close) 和 [`terminate()`](https://docs.python.org/zh-cn/3/library/multiprocessing.html#multiprocessing.pool.Pool.terminate)。 未做此类操作将导致进程在终结阶段挂起
  - 请注意依赖垃圾回收器来销毁进程池是 **不正确的** 做法，因为 CPython 并不保证进程池终结器会被调用（请参阅 [`object.__del__()`](https://docs.python.org/zh-cn/3/reference/datamodel.html#object.__del__) 来了解详情）



